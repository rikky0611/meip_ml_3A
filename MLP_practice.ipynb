{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist = fetch_mldata('MNIST original')\n",
    "mnist_X, mnist_y = shuffle(mnist.data, mnist.target.astype('int32'),\n",
    "                           random_state=42)\n",
    "\n",
    "# 輝度値のスケーリング\n",
    "mnist_X = mnist_X / 255.0\n",
    "# 今回は時間短縮のため1000個を使用\n",
    "mnist_X, mnist_y = mnist_X[:1000], mnist_y[:1000]\n",
    "# 学習データとテストデータに分ける\n",
    "train_X, test_X, train_y, test_y = train_test_split(mnist_X, mnist_y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=43)\n",
    "# one-of-k表現にする。\n",
    "train_y = np.eye(10)[train_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwg8k9X996IUba53UaQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106664e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_image(x, t, y=None):\n",
    "    x.resize(28, 28)\n",
    "    plt.imshow(x, 'gray')\n",
    "    if y is not None:\n",
    "        plt.title(\"true: {0}, pred: {1}\".format(t, y))\n",
    "    else:\n",
    "        plt.title(t)\n",
    "    plt.show()\n",
    "show_image(train_X[0], np.argmax(train_y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 活性化関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\" sigmoid function\n",
    "    \"\"\"\n",
    "    return ### WRITEME ###\n",
    "\n",
    "def derive_sigmoid(x):\n",
    "    \"\"\" derivative function of sigmoid\n",
    "    \"\"\"\n",
    "    return ### WRITEME ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レイヤー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, in_dim, out_dim, function, deriv_function):\n",
    "        self.W = np.random.uniform(low= -0.08, high= 0.08,\n",
    "                                                           size=(in_dim, out_dim)).astype(\"float32\") # 重み\n",
    "        self.b = np.zeros(out_dim).astype(\"float32\") # バイアス\n",
    "        self.function = function # 活性化関数\n",
    "        self.deriv_function = deriv_function # 活性化関数の微分\n",
    "        self.a = None\n",
    "        self.delta = None\n",
    "        \n",
    "    def f_prop(self, x):\n",
    "        \"\"\" feedforward\n",
    "        \"\"\"\n",
    "        \n",
    "        return ### WRITEME ###\n",
    "    \n",
    "    def b_prop(self, delta, W):\n",
    "        \"\"\" back propagation\n",
    "        \"\"\"\n",
    "\n",
    "        return ### WRITEME ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f_props(layers, x):\n",
    "    \"\"\" feedforward from input layer\n",
    "    \"\"\"\n",
    "    z = x\n",
    "    for layer in layers:\n",
    "        z = layer.f_prop(z)\n",
    "    return z\n",
    "\n",
    "def b_props(layers, delta):\n",
    "    \"\"\" back propagation from output layer\n",
    "    \"\"\"\n",
    "    for i, layer in enumerate(layers[::-1]):\n",
    "        if i == 0:\n",
    "            layer.delta = delta\n",
    "        else:\n",
    "            delta = layer.b_prop(delta, _W)\n",
    "        _W = layer.W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-6ea507456491>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-6ea507456491>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    delta = ### WRITEME ###\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def train(X, t, eps=0.001):\n",
    "    \"\"\" train on given minibatch\n",
    "    \"\"\"\n",
    "    # feed forward & back propagation\n",
    "    y = f_props(layers, X)\n",
    "    delta = ### WRITEME ###\n",
    "    b_props(layers, delta)\n",
    "\n",
    "    # update layer by layer\n",
    "    z = X\n",
    "    for i, layer in enumerate(layers):\n",
    "        dW = np.dot(z.T, layer.delta)\n",
    "        db = np.dot(np.ones(len(z)), layer.delta)\n",
    "        layer.W = layer.W - eps*dW\n",
    "        layer.b = layer.b - eps*db\n",
    "        z = layer.z\n",
    "\n",
    "def test(X, t):\n",
    "    \"\"\" feed forward on given minibatch\n",
    "    \"\"\"\n",
    "    y = f_props(layers, X)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3e4e6f266870>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mpred_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mpred_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_y\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "## set layer\n",
    "layers = [Layer(784, 100, sigmoid, derive_sigmoid), \n",
    "                Layer(100, 10, sigmoid, derive_sigmoid)]\n",
    "## train loop\n",
    "for epoch in range(10):\n",
    "    for x, y in zip(train_X, train_y):\n",
    "        train(x[np.newaxis, :], y[np.newaxis, :], eps=0.1)    \n",
    "    pred_y = test(test_X, test_y)\n",
    "    pred_y = [np.argmax(y) for y in pred_y]\n",
    "    print(\"accuracy: \", accuracy_score(pred_y, test_y))\n",
    "\n",
    "print(\"Finish Training\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
